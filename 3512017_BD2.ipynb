{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# University of Stirling\n",
    "\n",
    "# ITNPBD2 Representing and Manipulating Data\n",
    "\n",
    "# Assignment Autumn 2025\n",
    "\n",
    "# A Consultancy Job for JC Penney\n",
    "\n",
    "This notebook forms the assignment instructions and submission document of the assignment for ITNPBD2. Read the instructions carefully and enter code into the cells as indicated.\n",
    "\n",
    "You will need these five files, which were in the Zip file you downloaded from the course webpage:\n",
    "\n",
    "- jcpenney_reviewers.json\n",
    "- jcpenney_products.json\n",
    "- products.csv\n",
    "- reviews.csv\n",
    "- users.csv\n",
    "\n",
    "The data in these files describes products that have been sold by the American retail giant, JC Penney, and reviews by customers who bought them. Note that the product data is real, but the customer data is synthetic.\n",
    "\n",
    "Your job is to process the data, as requested in the instructions in the markdown cells in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completing the Assignment\n",
    "\n",
    "Rename this file to be xxxxxx_BD2 where xxxxxx is your student number, then type your code and narrative description into the boxes provided. Add as many code and markdown cells as you need. The cells should contain:\n",
    "\n",
    "- **Text narrative describing what you did with the data**\n",
    "- **The code that performs the task you have described**\n",
    "- **Comments that explain your code**\n",
    "\n",
    "The final structure (in PDF) of your report must:\n",
    "- **Start from the main insights observed (max 5 pages)**\n",
    "- **Include as an appendix the source code used for producing those insights (max 15 pages)**\n",
    "- **Include an AI cover sheet (provided on Canvas), which must contain a link to a versioned notebook file in OneDrive or another platform for version checks.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marking Scheme\n",
    "The assessment will be marked against the university Common Marking Scheme (CMS)\n",
    "\n",
    "Here is a summary of what you need to achieve to gain a grade in the major grade bands:\n",
    "\n",
    "|Grade|Requirement|\n",
    "|:---|:---|\n",
    "| Fail | You will fail if your code does not run or does not achieve even the basics of the task. You may also fail if you submit code without either comments or a text explanation of what the code does.|\n",
    "| Pass | To pass, you must submit sufficient working code to show that you have mastered the basics of the task, even if not everything works completely. You must include some justifications for your choice of methods, but without mentioning alternatives. |\n",
    "| Merit | For a merit, your code must be mostly correct, with only small problems or parts missing, and your comments must be useful rather than simply re-stating the code in English. Most choices for methods and structures should be explained and alternatives mentioned. |\n",
    "| Distinction | For a distinction, your code must be working, correct, and well commented and shows an appreciation of style, efficiency and reliability. All choices for methods and structures are concisely justified and alternatives are given well thought considerations. For a distinction, your work should be good enough to present to executives at the company.|\n",
    "\n",
    "The full details of the CMS can be found here\n",
    "\n",
    "https://www.stir.ac.uk/about/professional-services/student-academic-and-corporate-services/academic-registry/academic-policy-and-practice/quality-handbook/assessment-policy-and-procedure/appendix-2-postgraduate-common-marking-scheme/\n",
    "\n",
    "Note that this means there are not certain numbers of marks allocated to each stage of the assignment. Your grade will reflect how well your solutions and comments demonstrate that you have achieved the learning outcomes of the task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "When you are ready to submit, **print** your notebook as PDF (go to File -> Print Preview) in the Jupyter menu. Make sure you have run all the cells and that their output is displayed. Any lines of code or comments that are not visible in the pdf should be broken across several lines. You can then submit the file online.\n",
    "\n",
    "Late penalties will apply at a rate of three marks per day, up to a maximum of 7 days. After 7 days you will be given a mark of 0. Extensions will be considered under acceptable circumstances outside your control.\n",
    "\n",
    "## Academic Integrity\n",
    "\n",
    "This is an individual assignment, and so all submitted work must be fully your own work.\n",
    "\n",
    "The University of Stirling is committed to protecting the quality and standards of its awards. Consequently, the University seeks to promote and nurture academic integrity, support staff academic integrity, and support students to understand and develop good academic skills that facilitate academic integrity.\n",
    "\n",
    "In addition, the University deals decisively with all forms of Academic Misconduct.\n",
    "\n",
    "Where a student does not act with academic integrity, their work or behaviour may demonstrate Poor Academic Practice or it may represent Academic Misconduct.\n",
    "\n",
    "### Poor Academic Practice\n",
    "\n",
    "Poor Academic Practice is defined as: \"The submission of any type of assessment with a lack of referencing or inadequate referencing which does not effectively acknowledge the origin of words, ideas, images, tables, diagrams, maps, code, sound and any other sources used in the assessment.\"\n",
    "\n",
    "### Academic Misconduct\n",
    "\n",
    "Academic Misconduct is defined as: \"any act or attempted act that does not demonstrate academic integrity and that may result in creating an unfair academic advantage for you or another person, or an academic disadvantage for any other member or member of the academic community.\"\n",
    "\n",
    "Plagiarism is presenting somebody else’s work as your own **and includes the use of artificial intelligence tools beyond AIAS Level 2 or the use of Large Language Models.**. Plagiarism is a form of academic misconduct and is taken very seriously by the University. Students found to have plagiarised work can have marks deducted and, in serious cases, even be expelled from the University. Do not submit any work that is not entirely your own. Do not collaborate with or get help from anybody else with this assignment.\n",
    "\n",
    "The University of Stirling's full policy on Academic Integrity can be found at:\n",
    "\n",
    "https://www.stir.ac.uk/about/professional-services/student-academic-and-corporate-services/academic-registry/academic-policy-and-practice/quality-handbook/academic-integrity-policy-and-academic-misconduct-procedure/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Assignment\n",
    "Your task with this assignment is to use the data provided to demonstrate your Python data manipulation skills.\n",
    "\n",
    "There are three `.csv` files and two `.json` files so you can process different types of data. The files also contain unstructured data in the form of natural language in English and links to images that you can access from the JC Penney website (use the field called `product_image_urls`).\n",
    "\n",
    "Start with easy tasks to show you can read in a file, create some variables and data structures, and manipulate their contents. Then move onto something more interesting.\n",
    "\n",
    "Look at the data that we provided with this assessment and think of something interesting to do with it using whatever libraries you like. Describe what you decide to do with the data and why it might be interesting or useful to the company to do it.\n",
    "\n",
    "You can add additional data if you need to - either download it or access it using `requests`. Produce working code to implement your ideas in as many cells as you need below. There is no single right answer, the aim is to simply show you are competent in using python for data analysis. Exactly how you do that is up to you.\n",
    "\n",
    "For a distinction class grade, this must show originality, creative thinking, and insights beyond what you've been taught directly on the module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure\n",
    "You may structure the appendix of the project how you wish, but here is a suggested guideline to help you organise your work, based on the CRISP-DM data science methodology:\n",
    "\n",
    " 1. **Business understanding** - What business context is the data coming from? What insights would be valuable in that context, and what data would be required for that purporse? \n",
    " 2. **Data understanding and preparation** - Explore the data and show you understand its structure and relations, with the aid of appropriate visualisation techniques. Assess the data quality, which insights you would be able to answer from it, and what preparation the data would require. Add new data from another source if required to bring new insights to the data you already have.\n",
    " 3. **Data modeling (optional)** - Would modeling be required for the insights you have considered? Use appropriate techniques, if so.\n",
    " 4. **Evaluation and deployment** - How do the insights you obtained help the company, and how can should they be adopted in their business? If modeling techniques have been adopted, are their use scientifically sound and how should they be mantained?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remember to make sure you are working completely on your own.\n",
    "# Don't work in a group or with a friend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **JCPenny Consultancy Analysis**\n",
    "### **Date: 27/10/2025**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup Instructions\n",
    "\n",
    "## Setting up the Environment with Anaconda\n",
    "\n",
    "Follow these steps to set up your environment for running this Jupyter notebook:\n",
    "\n",
    "### 1. Clone the Repository (if applicable)\n",
    "```bash\n",
    "git clone https://github.com/yakubuaisha318-gif/Representation_and_Manipulation_of_Data_JC_Penny_Consultancy_Assignment.git\n",
    "cd Representation_and_Manipulation_of_Data_JC_Penny_Consultancy_Assignment\n",
    "```\n",
    "\n",
    "### 2. Install Anaconda\n",
    "If you haven't already installed Anaconda, download it from [anaconda.com](https://www.anaconda.com/products/distribution) and follow the installation instructions for your operating system.\n",
    "\n",
    "### 3. Create a New Conda Environment\n",
    "```bash\n",
    "conda create -n jcpenney-analysis python=3.9\n",
    "```\n",
    "\n",
    "### 4. Activate the Environment\n",
    "```bash\n",
    "conda activate jcpenney-analysis\n",
    "```\n",
    "\n",
    "### 5. Install Required Dependencies\n",
    "```bash\n",
    "pip install -r requrements.txt\n",
    "```\n",
    "\n",
    "If the requirements file is not available, install the necessary packages:\n",
    "```bash\n",
    "conda install pandas numpy matplotlib openpyxl\n",
    "pip install fpdf\n",
    "```\n",
    "\n",
    "### 6. Start Jupyter Notebook\n",
    "```bash\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "### 7. Open and Run This Notebook\n",
    "1. Navigate to this notebook file in the Jupyter interface\n",
    "2. Select the kernel: `Kernel` → `Change kernel` → `jcpenney-analysis`\n",
    "3. Run the cells: `Cell` → `Run All`\n",
    "\n",
    "### 8. Deactivating the Environment\n",
    "When you're done working:\n",
    "```bash\n",
    "conda deactivate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jcpenny_reviewers and users are same except for the extra information in jcpenney_reviewers\n",
      "jcpenney_reviewers has reviewed field\n",
      "I will be using jcpenney_reviewers for further processing\n",
      "Extra fields in jcpenney_reviewers: {'Reviewed'}\n",
      "Extra fields in users: set()\n",
      "{'Metric': ['Total Reviewers', 'Reviewers with Reviews', 'Reviewers without Reviews', 'Average Reviews per User', 'Total Products', 'Products with Ratings', 'Total Reviews', 'Average Product Rating', 'Median Product Rating', 'Average Review Score', 'Median Review Score'], 'Value': [5000, 4029, 971, np.float64(1.6), 7982, 7982, 39063, np.float64(2.99), np.float64(3.0), np.float64(1.49), np.float64(1.0)]}\n",
      "[{'Product ID': 'b6c0b6bea69c722939585baeac73c13d', 'Product Name': 'Alfred Dunner® Essential Pull On Capri Pant', 'Brand': 'Alfred Dunner', 'Category': 'alfred dunner', 'Average Rating': 2.625, 'Total Reviews': 8, 'Price': '$24.16', 'Image URL': 'http://s7d9.scene7.com/is/image/JCPenney/DP1228201517142050M.tif?hei=380&amp;wid=380&op_usm=.4,.8,0,0&resmode=sharp2&op_usm=1.5,.8,0,0&resmode=sharp'}, {'Product ID': '93e5272c51d8cce02597e3ce67b7ad0a', 'Product Name': 'Alfred Dunner® Essential Pull On Capri Pant', 'Brand': 'Alfred Dunner', 'Category': 'alfred dunner', 'Average Rating': 3.0, 'Total Reviews': 8, 'Price': '$24.16', 'Image URL': 'http://s7d9.scene7.com/is/image/JCPenney/DP1228201517142050M.tif?hei=380&amp;wid=380&op_usm=.4,.8,0,0&resmode=sharp2&op_usm=1.5,.8,0,0&resmode=sharp'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any, Tuple, Union, Set\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def convert_json_file_to_json_array(json_file_path):\n",
    "    '''\n",
    "    Convert a JSON Lines file to a JSON array.\n",
    "    '''\n",
    "    data = []\n",
    "    with open(json_file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line:  # Skip empty lines\n",
    "                try:\n",
    "                    data.append(json.loads(line))\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding JSON: {e}\")\n",
    "                    print(f\"Problematic line: {line[:100]}...\")  # Print first 100 chars of problematic line\n",
    "                    break\n",
    "    return data\n",
    "\n",
    "\n",
    "def convert_csv_file_to_json_array(csv_file_path):\n",
    "    '''\n",
    "    Convert a CSV file to a JSON array.\n",
    "    '''\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    return json.loads(df.to_json(orient=\"records\"))\n",
    "\n",
    "\n",
    "def get_reviews_by_username(username):\n",
    "    '''\n",
    "    Get reviews by username.\n",
    "    '''\n",
    "    reviews = convert_csv_file_to_json_array(\"reviews.csv\")\n",
    "    filtered_reviews = [review for review in reviews if review[\"Username\"] == username]\n",
    "    return filtered_reviews\n",
    "\n",
    "def get_extra_fields(dict1, dict2):\n",
    "    \"\"\"\n",
    "    Compare two dictionaries and return extra fields in each.\n",
    "    Returns a tuple of (extra_in_1, extra_in_2)\n",
    "    \"\"\"\n",
    "    keys1 = set(dict1.keys())\n",
    "    keys2 = set(dict2.keys())\n",
    "    return (keys1 - keys2, keys2 - keys1)\n",
    "\n",
    "\n",
    "def analyze_user_reviewing_patterns(reviewers_data: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"Analyze how many products each user has reviewed.\"\"\"\n",
    "    review_counts = [len(reviewer.get(\"Reviewed\", [])) for reviewer in reviewers_data]\n",
    "    \n",
    "    return {\n",
    "        \"total_reviewers\": len(reviewers_data),\n",
    "        \"reviewers_with_reviews\": len([c for c in review_counts if c > 0]),\n",
    "        \"reviewers_without_reviews\": len([c for c in review_counts if c == 0]),\n",
    "        \"average_reviews_per_user\": np.mean(review_counts) if review_counts else 0,\n",
    "        \"median_reviews_per_user\": np.median(review_counts) if review_counts else 0,\n",
    "        \"max_reviews_by_user\": np.max(review_counts) if review_counts else 0\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_values(data: List[Dict[str, Any]], field_name: str, value_type: str = \"float\") -> List[Union[float, int]]:\n",
    "    \"\"\"Extract numeric values from a field in a list of dictionaries.\"\"\"\n",
    "    values = []\n",
    "    for item in data:\n",
    "        value_str = item.get(field_name)\n",
    "        if value_str is not None:\n",
    "            try:\n",
    "                if value_type == \"int\":\n",
    "                    values.append(int(value_str))\n",
    "                else:\n",
    "                    values.append(float(value_str))\n",
    "            except (ValueError, TypeError):\n",
    "                pass\n",
    "    return values\n",
    "\n",
    "\n",
    "def analyze_numeric_data(products_data: List[Dict[str, Any]], field_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"Analyze numeric data across all products.\"\"\"\n",
    "    values = extract_values(products_data, field_name)\n",
    "    \n",
    "    if not values:\n",
    "        return {}\n",
    "    \n",
    "    return {\n",
    "        \"count\": len(values),\n",
    "        \"mean\": np.mean(values),\n",
    "        \"median\": np.median(values),\n",
    "        \"std\": np.std(values),\n",
    "        \"min\": np.min(values),\n",
    "        \"max\": np.max(values),\n",
    "        \"quartiles\": {\n",
    "            \"25%\": np.percentile(values, 25),\n",
    "            \"50%\": np.percentile(values, 50),\n",
    "            \"75%\": np.percentile(values, 75)\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def create_summary_data(jcpenney_reviewers: List[Dict[str, Any]], \n",
    "                        jcpenney_products: List[Dict[str, Any]], \n",
    "                        reviews: List[Dict[str, Any]]) -> Dict[str, List[Any]]:\n",
    "    \"\"\"Create summary statistics data.\"\"\"\n",
    "    user_patterns = analyze_user_reviewing_patterns(jcpenney_reviewers)\n",
    "    product_ratings = analyze_numeric_data(jcpenney_products, \"average_product_rating\")\n",
    "    review_scores = analyze_numeric_data(reviews, \"Score\")\n",
    "    \n",
    "    return {\n",
    "        \"Metric\": [\n",
    "            \"Total Reviewers\", \n",
    "            \"Reviewers with Reviews\", \n",
    "            \"Reviewers without Reviews\",\n",
    "            \"Average Reviews per User\",\n",
    "            \"Total Products\",\n",
    "            \"Products with Ratings\",\n",
    "            \"Total Reviews\",\n",
    "            \"Average Product Rating\",\n",
    "            \"Median Product Rating\",\n",
    "            \"Average Review Score\",\n",
    "            \"Median Review Score\"\n",
    "        ],\n",
    "        \"Value\": [\n",
    "            len(jcpenney_reviewers),\n",
    "            user_patterns[\"reviewers_with_reviews\"],\n",
    "            user_patterns[\"reviewers_without_reviews\"],\n",
    "            round(user_patterns[\"average_reviews_per_user\"], 2),\n",
    "            len(jcpenney_products),\n",
    "            len([p for p in jcpenney_products if p.get(\"average_product_rating\") is not None]),\n",
    "            len(reviews),\n",
    "            round(product_ratings.get(\"mean\", 0), 2),\n",
    "            round(product_ratings.get(\"median\", 0), 2),\n",
    "            round(review_scores.get(\"mean\", 0), 2),\n",
    "            round(review_scores.get(\"median\", 0), 2)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def create_product_data(products: List[Dict[str, Any]], include_image_url: bool = False) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Create standardized product data for Excel sheets.\"\"\"\n",
    "    product_data = []\n",
    "    for product in products:\n",
    "        data = {\n",
    "            \"Product ID\": product.get(\"uniq_id\", \"\"),\n",
    "            \"Product Name\": product.get(\"name_title\", \"\")[:50],\n",
    "            \"Brand\": product.get(\"brand\", \"\"),\n",
    "            \"Category\": product.get(\"category\", \"\"),\n",
    "            \"Average Rating\": product.get(\"average_product_rating\", \"\"),\n",
    "            \"Total Reviews\": product.get(\"total_number_reviews\", \"\"),\n",
    "            \"Price\": f\"${product.get('sale_price', 'N/A')}\"\n",
    "        }\n",
    "        if include_image_url:\n",
    "            data[\"Image URL\"] = product.get(\"product_image_urls\", \"\")\n",
    "        product_data.append(data)\n",
    "    return product_data\n",
    "\n",
    "\n",
    "def get_top_products(products_data: List[Dict[str, Any]], sort_field: str, top_n: int = 10, reverse: bool = True) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Get top products based on a specified field.\"\"\"\n",
    "    valid_products = []\n",
    "    for p in products_data:\n",
    "        field_value = p.get(sort_field)\n",
    "        if field_value is not None:\n",
    "            try:\n",
    "                float(field_value) if sort_field == \"average_product_rating\" else int(field_value)\n",
    "                valid_products.append(p)\n",
    "            except (ValueError, TypeError):\n",
    "                pass\n",
    "    \n",
    "    sorted_products = sorted(valid_products, \n",
    "                           key=lambda x: float(x[sort_field]) if sort_field == \"average_product_rating\" else int(x[sort_field]), \n",
    "                           reverse=reverse)\n",
    "    \n",
    "    return sorted_products[:top_n]\n",
    "\n",
    "\n",
    "def analyze_performance_by_field(products_data: List[Dict[str, Any]], field_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"Analyze performance by a specified field (brand or category).\"\"\"\n",
    "    field_stats = defaultdict(list)\n",
    "    \n",
    "    for product in products_data:\n",
    "        field = product.get(field_name)\n",
    "        rating_str = product.get(\"average_product_rating\")\n",
    "        reviews_str = product.get(\"total_number_reviews\")\n",
    "        \n",
    "        if field and rating_str is not None and reviews_str is not None:\n",
    "            try:\n",
    "                rating = float(rating_str)\n",
    "                reviews = int(reviews_str)\n",
    "                field_stats[field].append({\n",
    "                    \"rating\": rating,\n",
    "                    \"reviews\": reviews\n",
    "                })\n",
    "            except (ValueError, TypeError):\n",
    "                pass\n",
    "    \n",
    "    field_analysis = {}\n",
    "    for field, products in field_stats.items():\n",
    "        ratings = [p[\"rating\"] for p in products]\n",
    "        review_counts = [p[\"reviews\"] for p in products]\n",
    "        \n",
    "        field_analysis[field] = {\n",
    "            \"product_count\": len(products),\n",
    "            \"avg_rating\": np.mean(ratings),\n",
    "            \"median_rating\": np.median(ratings),\n",
    "            \"total_reviews\": sum(review_counts),\n",
    "            \"avg_reviews_per_product\": np.mean(review_counts)\n",
    "        }\n",
    "    \n",
    "    sorted_fields = sorted(field_analysis.items(), key=lambda x: x[1][\"avg_rating\"], reverse=True)\n",
    "    \n",
    "    return dict(sorted_fields)\n",
    "\n",
    "\n",
    "def main():\n",
    "    jcpenney_reviewers = convert_json_file_to_json_array(\"jcpenney_reviewers.json\")\n",
    "    jcpenney_products = convert_json_file_to_json_array(\"jcpenney_products.json\")\n",
    "    reviews = convert_csv_file_to_json_array(\"reviews.csv\")\n",
    "    products = convert_csv_file_to_json_array(\"products.csv\")\n",
    "    users = convert_csv_file_to_json_array(\"users.csv\")\n",
    "\n",
    "    jcpenney_reviewers_usernames = [reviewer[\"Username\"] for reviewer in jcpenney_reviewers]\n",
    "    users_usernames = [user[\"Username\"] for user in users]\n",
    "\n",
    "    jcpenney_products_uniq_ids = [product[\"uniq_id\"] for product in jcpenney_products]\n",
    "    products_uniq_ids = [product[\"Uniq_id\"] for product in products]\n",
    "\n",
    "    if set(jcpenney_reviewers_usernames).issubset(set(users_usernames)) and len(jcpenney_reviewers_usernames) == len(users_usernames):\n",
    "        print(\"jcpenny_reviewers and users are same except for the extra information in jcpenney_reviewers\")\n",
    "        print(\"jcpenney_reviewers has reviewed field\")\n",
    "        print(\"I will be using jcpenney_reviewers for further processing\")\n",
    "        extra_in_reviewers, extra_in_users = get_extra_fields(jcpenney_reviewers[0], users[0])\n",
    "        print(\"Extra fields in jcpenney_reviewers:\", extra_in_reviewers)\n",
    "        print(\"Extra fields in users:\", extra_in_users)\n",
    "\n",
    "    if set(jcpenney_products_uniq_ids).issubset(set(products_uniq_ids)) and len(jcpenney_products_uniq_ids) == len(products_uniq_ids):\n",
    "        print(\"jcpenney_products and products are same except for the extra information in jcpenney_products\")\n",
    "        print(\"jcpenney_products has Reviews field\")\n",
    "        print(\"I will be using jcpenney_products for further processing\")\n",
    "        extra_in_jcpenney, extra_in_products = get_extra_fields(jcpenney_products[0], products[0])\n",
    "        print(\"\\nExtra fields in jcpenney_products:\", extra_in_jcpenney)\n",
    "        print(\"Extra fields in products:\", extra_in_products)\n",
    "\n",
    "    print(create_summary_data(jcpenney_reviewers, jcpenney_products, reviews))\n",
    "    print(create_product_data(jcpenney_products, include_image_url=True)[:2])\n",
    "    # print(\"number of reviewers:\", len(jcpenney_reviewers))\n",
    "    # print(\"number of jcpenney products:\", len(jcpenney_products))\n",
    "    # # print(\"number of reviews:\", len(reviews))\n",
    "    # print(\"number of products:\", len(products))\n",
    "    # print(\"number of users:\", len(users))\n",
    "\n",
    "    # print(jcpenney_reviewers[0])\n",
    "    # print(jcpenney_products[0])\n",
    "    # print(type(jcpenney_reviewers))\n",
    "    # for key in jcpenney_reviewers[0].keys():\n",
    "    #     print(\"reviewer_keys:\", key)\n",
    "    # print(jcpenney_products[0].get(\"Reviews\"))\n",
    "    # print(type(jcpenney_products))\n",
    "    # for key in jcpenney_products[0].keys():\n",
    "    #     print(\"product_keys:\", key)\n",
    "    # print(type(reviews))\n",
    "    # for key in reviews[0].keys():\n",
    "    #     print(\"review_keys:\", key)\n",
    "    # print(type(products))\n",
    "    # for key in products[0].keys():\n",
    "    #     print(\"product_keys:\", key)\n",
    "    # print(type(users))\n",
    "    # for key in users[0].keys():\n",
    "    #     print(\"user_keys:\", key)\n",
    "\n",
    "\n",
    "# print(\"Uniq_id:\", data[0][\"uniq_id\"])\n",
    "# print(\"SKU:\", data[0][\"sku\"])\n",
    "# print(\"Name:\", data[0][\"name_title\"])\n",
    "# print(\"List_price:\", data[0][\"list_price\"])\n",
    "# print(\"Sale_price:\", data[0][\"sale_price\"])\n",
    "# print(\"Category:\", data[0][\"category\"])\n",
    "# print(\"Category_tree:\", data[0][\"category_tree\"])\n",
    "# print(\"Average_product_rating:\", data[0][\"average_product_rating\"])\n",
    "# print(\"Product_url:\", data[0][\"product_url\"])\n",
    "# print(\"Description:\", data[0][\"description\"])\n",
    "# print(\"Product_image_urls:\", data[0][\"product_image_urls\"])\n",
    "# print(\"Bought With:\", data[0][\"Bought With\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
